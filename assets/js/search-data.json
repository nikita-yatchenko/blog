{
  
    
        "post0": {
            "title": "Named Entity Recognition using LSTM in Keras",
            "content": "Introduction . Named Entity Recognition can be used as a standalone tool but also as a preprocessing toolfor later applications in Machine Translation, Customer Feedback Hanlding, and even Text Summarization. . 1. Import Modules . %matplotlib inline import matplotlib.pyplot as plt import pandas as pd import numpy as np np.random.seed(0) plt.style.use(&quot;ggplot&quot;) import tensorflow as tf print(&#39;Tensorflow version:&#39;, tf.__version__) print(&#39;GPU detected:&#39;, tf.config.list_physical_devices(&#39;GPU&#39;)) . Tensorflow version: 2.3.0 GPU detected: [] . . . Collecting livelossplot Downloading livelossplot-0.5.3-py3-none-any.whl (30 kB) Requirement already satisfied: matplotlib in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from livelossplot) (3.3.3) Requirement already satisfied: ipython in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from livelossplot) (7.19.0) Collecting bokeh Downloading bokeh-2.2.3.tar.gz (8.8 MB) Requirement already satisfied: python-dateutil&gt;=2.1 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from bokeh-&gt;livelossplot) (2.8.1) Requirement already satisfied: Jinja2&gt;=2.7 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from bokeh-&gt;livelossplot) (2.11.2) Requirement already satisfied: numpy&gt;=1.11.3 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from bokeh-&gt;livelossplot) (1.19.2) Requirement already satisfied: pillow&gt;=7.1.0 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from bokeh-&gt;livelossplot) (8.1.0) Requirement already satisfied: packaging&gt;=16.8 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from bokeh-&gt;livelossplot) (20.8) Requirement already satisfied: tornado&gt;=5.1 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from bokeh-&gt;livelossplot) (6.1) Requirement already satisfied: typing_extensions&gt;=3.7.4 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from bokeh-&gt;livelossplot) (3.7.4.3) Requirement already satisfied: MarkupSafe&gt;=0.23 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from Jinja2&gt;=2.7-&gt;bokeh-&gt;livelossplot) (1.1.1) Requirement already satisfied: pyparsing&gt;=2.0.2 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from packaging&gt;=16.8-&gt;bokeh-&gt;livelossplot) (2.4.7) Requirement already satisfied: six&gt;=1.5 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from python-dateutil&gt;=2.1-&gt;bokeh-&gt;livelossplot) (1.15.0) Collecting PyYAML&gt;=3.10 Downloading PyYAML-5.4-cp38-cp38-win_amd64.whl (213 kB) Requirement already satisfied: pickleshare in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (0.7.5) Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (3.0.8) Requirement already satisfied: decorator in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (4.4.2) Requirement already satisfied: pygments in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (2.7.4) Requirement already satisfied: traitlets&gt;=4.2 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (5.0.5) Requirement already satisfied: jedi&gt;=0.10 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (0.18.0) Requirement already satisfied: backcall in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (0.2.0) Requirement already satisfied: colorama in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (0.4.4) Requirement already satisfied: setuptools&gt;=18.5 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from ipython-&gt;livelossplot) (51.1.2.post20210112) Collecting parso&lt;0.9.0,&gt;=0.8.0 Downloading parso-0.8.1-py2.py3-none-any.whl (93 kB) Requirement already satisfied: wcwidth in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;livelossplot) (0.2.5) Requirement already satisfied: ipython-genutils in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from traitlets&gt;=4.2-&gt;ipython-&gt;livelossplot) (0.2.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from matplotlib-&gt;livelossplot) (1.3.1) Requirement already satisfied: cycler&gt;=0.10 in c: users nikita.yatchenko miniconda3 envs deeplearning lib site-packages (from matplotlib-&gt;livelossplot) (0.10.0) Building wheels for collected packages: bokeh Building wheel for bokeh (setup.py): started Building wheel for bokeh (setup.py): still running... Building wheel for bokeh (setup.py): finished with status &#39;done&#39; Created wheel for bokeh: filename=bokeh-2.2.3-py3-none-any.whl size=9296317 sha256=03d6648c796e7706173bfb3b108d2019c847e9c9fd4be75a2698aa7d0e9b3170 Stored in directory: c: users nikita.yatchenko appdata local pip cache wheels 44 48 ac 5cde9e6d0b1e0afb4cff564eaf59462468abe37cfc83cbb5ed Successfully built bokeh Installing collected packages: parso, PyYAML, bokeh, livelossplot Attempting uninstall: parso Found existing installation: parso 0.7.0 Uninstalling parso-0.7.0: Successfully uninstalled parso-0.7.0 Successfully installed PyYAML-5.4 bokeh-2.2.3 livelossplot-0.5.3 parso-0.8.1 . 2. Explore NER Dataset . This dataset contains of course sentences in English but they also have corresponding annotations for each word. The sentence in dataset are encoded in Latin 1. . Essential info about entities: . geo = Geographical Entity | org = Organization | per = Person | gpe = Geopolitical Entity | tim = Time indicator | art = Artifact | eve = Event | nat = Natural Phenomenon | . Total Words Count = 1354149 . Target Data Column: “tag” . data = pd.read_csv(&quot;data/ner_dataset.csv&quot;, encoding=&quot;latin1&quot;) data = data.fillna(method=&quot;ffill&quot;) data.head(25) . Sentence # Word POS Tag . 0 Sentence: 1 | Thousands | NNS | O | . 1 Sentence: 1 | of | IN | O | . 2 Sentence: 1 | demonstrators | NNS | O | . 3 Sentence: 1 | have | VBP | O | . 4 Sentence: 1 | marched | VBN | O | . 5 Sentence: 1 | through | IN | O | . 6 Sentence: 1 | London | NNP | B-geo | . 7 Sentence: 1 | to | TO | O | . 8 Sentence: 1 | protest | VB | O | . 9 Sentence: 1 | the | DT | O | . 10 Sentence: 1 | war | NN | O | . 11 Sentence: 1 | in | IN | O | . 12 Sentence: 1 | Iraq | NNP | B-geo | . 13 Sentence: 1 | and | CC | O | . 14 Sentence: 1 | demand | VB | O | . 15 Sentence: 1 | the | DT | O | . 16 Sentence: 1 | withdrawal | NN | O | . 17 Sentence: 1 | of | IN | O | . 18 Sentence: 1 | British | JJ | B-gpe | . 19 Sentence: 1 | troops | NNS | O | . 20 Sentence: 1 | from | IN | O | . 21 Sentence: 1 | that | DT | O | . 22 Sentence: 1 | country | NN | O | . 23 Sentence: 1 | . | . | O | . 24 Sentence: 2 | Families | NNS | O | . The column of interest is the rightmost one - where we see the tag for each word. Let&#39;s check out the number of unique words in the corpus and number of unique tags: . print(&quot;Unique words in corpus:&quot;, data[&#39;Word&#39;].nunique()) print(&quot;Unique tags in corpus:&quot;, data[&#39;Tag&#39;].nunique()) . Unique words in corpus: 35178 Unique tags in corpus: 17 . Create a list of unique words . words = list(set(data.Word.values)) words.append(&quot;ENDPAD&quot;) # end of sentence ? num_words = len(words) . words[0] . &#39;plucked&#39; . Similar process for target variable (tags) . tags = list(set(data.Tag.values)) num_tags = len(tags) . Now, we are gonna modify our dataset so that we can easily split our dataset into our feature matrix and the target vector. So we want to create two pools (containing 3 values) for each sentence so that the 1st value in the two pools is the word and the 2nd value is the POS(Part of Speech) and 3rd is Tag i.e. class name. . 3. Retrieve Sentences and Corresponding Tags . Let&#39;s retreive sentences and their corresponding tags in a nice format in order to have a clear input and a clear output for our Recurrent Neural Network. . First, we group given data by sentences. Then we apply lambda function that extracts Word, POS, and TAG for each grouped sentence to create a list of tuples with a structure: (Word to POS to TAG). . class SentenceGetter(): def __init__(self, data): self.n_sent = 1 self.data = data self.empty = False agg_func = lambda s : [(w, p, t) for w, p, t in zip(s[&#39;Word&#39;].values.tolist(), s[&#39;POS&#39;].values.tolist(), s[&#39;Tag&#39;].values.tolist())] self.grouped = self.data.groupby(&#39;Sentence #&#39;).apply(agg_func) self.sentences = [s for s in self.grouped] def get_next(self): try: s = self.grouped[&quot;Sentence: {}&quot;.format(self.n_sent)] self.n_sent += 1 return s except: return None . getter = SentenceGetter(data) sentences = getter.sentences . Observe that the first sentence countains the exact information we wanted: . sentences[0] . [(&#39;Thousands&#39;, &#39;NNS&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;IN&#39;, &#39;O&#39;), (&#39;demonstrators&#39;, &#39;NNS&#39;, &#39;O&#39;), (&#39;have&#39;, &#39;VBP&#39;, &#39;O&#39;), (&#39;marched&#39;, &#39;VBN&#39;, &#39;O&#39;), (&#39;through&#39;, &#39;IN&#39;, &#39;O&#39;), (&#39;London&#39;, &#39;NNP&#39;, &#39;B-geo&#39;), (&#39;to&#39;, &#39;TO&#39;, &#39;O&#39;), (&#39;protest&#39;, &#39;VB&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;DT&#39;, &#39;O&#39;), (&#39;war&#39;, &#39;NN&#39;, &#39;O&#39;), (&#39;in&#39;, &#39;IN&#39;, &#39;O&#39;), (&#39;Iraq&#39;, &#39;NNP&#39;, &#39;B-geo&#39;), (&#39;and&#39;, &#39;CC&#39;, &#39;O&#39;), (&#39;demand&#39;, &#39;VB&#39;, &#39;O&#39;), (&#39;the&#39;, &#39;DT&#39;, &#39;O&#39;), (&#39;withdrawal&#39;, &#39;NN&#39;, &#39;O&#39;), (&#39;of&#39;, &#39;IN&#39;, &#39;O&#39;), (&#39;British&#39;, &#39;JJ&#39;, &#39;B-gpe&#39;), (&#39;troops&#39;, &#39;NNS&#39;, &#39;O&#39;), (&#39;from&#39;, &#39;IN&#39;, &#39;O&#39;), (&#39;that&#39;, &#39;DT&#39;, &#39;O&#39;), (&#39;country&#39;, &#39;NN&#39;, &#39;O&#39;), (&#39;.&#39;, &#39;.&#39;, &#39;O&#39;)] . 4. Define Mapping Between Words and Numbers; Between Tags and Numbers . To build an RNN we need to represent words and tags as vectors, or at least as numerical representations (values or indecies). . word2idx = {w : i for i, w in enumerate(words)} tag2idx = {t : i for i, t in enumerate(tags)} . import pandas as pd pd.DataFrame.from_dict(word2idx, orient = &#39;index&#39;).tail() . 0 . Socialists 35174 | . bolstering 35175 | . One-third 35176 | . author 35177 | . ENDPAD 35178 | . We can retrieve these words using their indices and looking them up in the dictionary and returing the corresponding keys. . 5. Padding Input Sentences and Creating Train / Test Splits . To build a Recurrent Neural Netowork we need to be able to use equal length sentences (technical necessity of Keras / Tensorflow packages). Thus we are goin to pad our sentences to a prescribed length. So what will this length be? Let us first look at the distribution of sentences&#39; length - look at the histogram. . print(&quot;Total number of sentences = &quot; + str(len(sentences))) _ = plt.hist([len(s) for s in sentences], bins = 50) print(&quot;Mean of the distribution is &quot; + str(sum([len(s) for s in sentences])/ len(sentences))) print(&quot;IQ range (10% to 99%) of the distribution is &quot; + str(np.percentile([len(s) for s in sentences], [10, 99]))) . Total number of sentences = 47959 Mean of the distribution is 21.863987989741236 IQ range (10% to 99%) of the distribution is [12. 43.] . Looking at the plot, considering the mean, the IQ ranges we can observe that maxing out at the length 50 should capture a vast moajority of sentences. . 5.1 Padding . X is going to be a numerical representation of our words for each sentence (we could potentially use a far better word to vector embedding). Iterate over each word to get a corresponding value for that word. . To pad we will use pad_sequence function from the Tensorflow package, where we will specify the maxlen parameter to indicate maximum length each sentences will have and a value parameter - what we are padding with. . from tensorflow.keras.preprocessing.sequence import pad_sequences max_len = 50 X = [[word2idx[w[0]] for w in s] for s in sentences] X = pad_sequences(maxlen = max_len, sequences = X, padding = &#39;post&#39;, value=num_words-1) y = [[tag2idx[w[2]] for w in s] for s in sentences] y = pad_sequences(maxlen = max_len, sequences = y, padding = &#39;post&#39;, value=tag2idx[&#39;O&#39;]) . Let&#39;s split the dataset into training and testing to test our final model&#39;s performance. Let&#39;s set the test size at 20%. . from sklearn.model_selection import train_test_split X_train, X_test, _train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1) . 6. Bidirectional LSTM Model . In this section we are going to build an architecture for the predictive model. Some of the questions pertaining to the model&#39;s architecture: . Why use Bidirectional model? . Bidirectional model allows us to make use not only of the past information but also of the future information. Meaning, if we are at node 5 (word 5), we not only use information about previous 4 words, but also take into account what relationships are present in words 6 - 50. | . Why use LSTM and not just simple RNN? . Regular RNN has a few major drawbacks: vanishing moments, and they are heavily influenced by close dependencies. LSTM addresses both problems by indroducing a &quot;memory cell&quot;, which better stores information from the past and at each next node, LSTM considers whether to use more current information or weigh in more towards the past. | unites are ~ channels (think of various interpretations / features of that particular spot in a sequence) | so LSTM can either return (N observations, time-steps, features / channels) | return_sequences = True (many-to-many) has the effect of each LSTM unit returning a sequence of y_lenth outputs (aka time-steps != 1), one for each time step in the input data, instead of single output value if return_sequences = False (many-to-one). | . helpful links: (https://stackoverflow.com/questions/38714959/understanding-keras-lstms/50235563#50235563, https://datascience.stackexchange.com/questions/10836/the-difference-between-dense-and-timedistributeddense-of-keras, ind helpful: https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/) . Why use Embedding layer? . In the Embedding layer words are represented by dense vectors where a vector represents the projection of the word (input vector space) into a continuous vector space (output vector space). | . Why use TimeDistributed layer? . Applies something (we specify this to be a dense layer) to each time step vector individually. Distribute dense layer calculation across time! If we get 700 (h_1, h_2, ... h_700) LSTM vectors (1 - observation, time-step, 200 - channels) - with the dense layer we collapse it to (1, 1) - for the first observation at time-step 1 | . What is and why use SpatialDropout? . Drops entire 1D feature maps instead of individual elements (used in convolution). So after embedding we have each word represented by a 1x50 vector. SpatialDropout will then take 10% of those channels and zero them out across ALL words. This is done to avoid co-adaptpation - forming a dependency group from one channel to another - a regularization method https://stackoverflow.com/questions/50393666/how-to-understand-spatialdropout1d-and-when-to-use-it | . from tensorflow.keras import Model, Input from tensorflow.keras.layers import LSTM, Embedding, Dense from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional . Let us first define an input shape. In keras we use Input to tell our model what object size is going through its pipeline. In this case, we are going to have an object of shape max length of a sentence, currently set to 50. Comma is there to indicate that it is not an integer, but a shape of an array. . Then we go on to the Embedding layer. This layer creates dense layers from sparse word vectors using word2vec or GloVe algorithms / methodologies. We can again think of this as creating new channels to represent word (not necessaryly, but each channel can tell us the word&#39;s plurality or singularity, masculine or feminine, has some connotation estimation as so on). . In order to avoid overfitting by creating dependencies between those channels (let&#39;s say the model has picked up that combining channel 30 with channel 47 produces lower loss), we break those dependencies by introducing a SpatialDropout layer, which nulls out the entire channel. . Next, we go on to creating Bidirection LSTM layer - LSTM&#39;s units - in the output # of channels - I think of it as different insights LSTM got from analyzing data, sort of like new features or hidden units in a regular NN. We must declare return_sequences = True, as we are interested in obtaining output vectors for every time step (many-to-many). . Finally, we need to convert Bidirectional LSTM&#39;s channels into tags, thus we need to apply a simple Dense layer to EACH time step. That is why we use Time-distributed layer. It applies Dense layer (with the same weights) to ALL time steps to produce a singular output - Tag with the highest probability after softmax. . input_word = Input(shape=(max_len,)) # batch of max_len dimensional vectors # model model = Embedding(input_dim = num_words, output_dim = 50, input_length = max_len)(input_word) model = SpatialDropout1D(0.1)(model) # drops entire 1D feature maps instead of individual elements model = Bidirectional(LSTM(units = 100, return_sequences = True, recurrent_dropout = 0.1))(model) # units - dimensions of the output 1 word (after embedding 1 x 250) becomes (1 x 100) after LSTM out = TimeDistributed(Dense(num_tags, activation = &#39;softmax&#39;))(model) # probability of each word being eah tag model = Model(input_word, out) model.summary() . Model: &#34;functional_9&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_6 (InputLayer) [(None, 50)] 0 _________________________________________________________________ embedding_5 (Embedding) (None, 50, 50) 1758950 _________________________________________________________________ spatial_dropout1d_4 (Spatial (None, 50, 50) 0 _________________________________________________________________ bidirectional_5 (Bidirection (None, 50, 200) 120800 _________________________________________________________________ time_distributed_5 (TimeDist (None, 50, 17) 3417 ================================================================= Total params: 1,883,167 Trainable params: 1,883,167 Non-trainable params: 0 _________________________________________________________________ . The model produces a total of 1,883,167 parameters. How exactly are they calculated? Let&#39;s find out: . # gate and cell state calculation we have a set of 2 matricies: matrix that deals with a hidden unit at time step t-1 and matrix that # deals with an input x_t. So we have 4 sets of parameters and each has 2 matricies: lstm_num_params = 4 * (100 * 50 + 100 * 100 + 100) print(&#39;Number of LSTM parameters: &#39;, lstm_num_params) # Now deal with the bidirectional part. We are going to end up having 2 hidden unit from 2 directions: forward and backward. print(&#39;Number of Bidirection LSTM parameters: &#39;, 2 * lstm_num_params) # time distributed / dense layer: output_size * (input_size + 1) - because of the bias + 1 dense_num_params = 2 * 17 * (100) + 17 # maybe same bias unit is applied to both forward and backward print(&#39;Number of Time-Distributed Dense parameters: &#39;, dense_num_params) . Number of LSTM parameters: 60400 Number of Bidirection LSTM parameters: 120800 Number of Time-Distributed Dense parameters: 3417 . Next, let&#39;s compile a model. We are using the most popular optimizer algorithm - Adam, out loss function is sparse categorical cross entropy (classes are mutually exclusive), and out metric is accuracy . model.compile(optimizer = &#39;adam&#39;, loss = &#39;sparse_categorical_crossentropy&#39;, metrics=[&quot;accuracy&quot;]) # what is sparse_categorical_crossentropy . Time to train and test our model. By importing ModelCheckpoint we can save the best model, monitor our calidation loss. Early Stopping allows us to early stop when we do not continue to improve on our model after 2 batches. Finally, PlotLossesCallback is a wayt to visualize our loss. . from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping from livelossplot.inputs.tf_keras import PlotLossesCallback . chkpt = ModelCheckpoint(&quot;model_weights.h5&quot;, monitor=&#39;val_loss&#39;,verbose=1, save_best_only=True, save_weights_only=True, mode=&#39;min&#39;) early_stopping = EarlyStopping(monitor=&#39;val_accuracy&#39;, min_delta=0, patience=2, verbose=0, mode=&#39;max&#39;, baseline=None, restore_best_weights=False) my_callbacks = [PlotLossesCallback(), chkpt, early_stopping] history = model.fit( x=X_train, y=y_train, validation_data=(X_test,y_test), batch_size=32, epochs=3, verbose=1, callbacks = my_callbacks ) . accuracy training (min: 0.958, max: 0.989, cur: 0.989) validation (min: 0.981, max: 0.985, cur: 0.985) Loss training (min: 0.037, max: 0.181, cur: 0.037) validation (min: 0.049, max: 0.068, cur: 0.049) Epoch 00003: val_loss improved from 0.05168 to 0.04879, saving model to model_weights.h5 1199/1199 [==============================] - 133s 111ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0488 - val_accuracy: 0.9853 . model.evaluate(X_test, y_test) . 300/300 [==============================] - 4s 14ms/step - loss: 0.0488 - accuracy: 0.9853 . [0.04879415035247803, 0.9853190183639526] . i = np.random.randint(0, X_test.shape[0]) # 659 p = model.predict(np.array([X_test[i]])) p = np.argmax(p, axis=-1) y_true = y_test[i] print(&quot;{:15}{:5} t {} n&quot;.format(&quot;Word&quot;, &quot;True&quot;, &quot;Pred&quot;)) print(&quot;-&quot; *30) for w, true, pred in zip(X_test[i], y_true, p[0]): print(&quot;{:15}{} t{}&quot;.format(words[w], tags[true], tags[pred])) . Word True Pred She O O remains O O hospitalized O O . O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O ENDPAD O O .",
            "url": "https://nikita-yatchenko.github.io/blog/2021/01/21/Named-Entity-Recognition.html",
            "relUrl": "/2021/01/21/Named-Entity-Recognition.html",
            "date": " • Jan 21, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://nikita-yatchenko.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://nikita-yatchenko.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nikita-yatchenko.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nikita-yatchenko.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}